import numpy as np

from evo.tools.settings import SETTINGS
from evo.tools import file_interface
from evo.core import metrics
from evo.tools import log
from evo.core import sync
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import FileResponse
import pprint
import copy
import pandas as pd
import itertools
import os
import time
import subprocess
import math
import glob
# import shutil
import matplotlib.pyplot as plt



SETTINGS.plot_usetex = False
log.configure_logging(verbose=True, debug=True, silent=False)
# ----------Required configuration--------------
# Specify location of ADB tool on server
adb_location = ""
# Specify name of package for playback app (see Unity Project Settings>Player>Other Settings>Package Name)
playback_package_name = ""
# Specify folder on server for files generated by SiTAR
SiTAR_folder = ""
# Hard code number of playbacks here if desired
num_playbacks = ""
# ----------------------------------------------


def get_length(filename):
    result = subprocess.run(["ffprobe", "-v", "error", "-show_entries",
                             "format=duration", "-of",
                             "default=noprint_wrappers=1:nokey=1", filename], 
                            stdout=subprocess.PIPE, 
                            stderr=subprocess.STDOUT)
    return float(result.stdout)


# app = FastAPI()

# # Method to handle receipt of sequence recording and transfer to playback AR device
# @app.post("/recording")
# def upload(recording: UploadFile = File(...)):
#     try:
#         contents = recording.file.read()
#         with open(recording.filename, 'wb') as f:
#             f.write(contents)
#     except Exception:
#         return {"message": "There was an error uploading the file"}
#     finally:
#         recording.file.close()
    
#     # Calculate length of mp4 for wait time
#     wait_time = (math.ceil(get_length("arcore-session.mp4")))*5  

#     # Push sequence mp4 to playback AR device via ADB and run playback app
#     os.system(adb_location + "adb push " + SiTAR_folder + "arcore-session.mp4 /sdcard/Android/data/" + playback_package_name + "/files")
#     os.system(adb_location + "adb shell monkey -p " + playback_package_name + " 1")
    
#     # (Optional) Create timestamped folder in SiTAR folder if want to save data
#     #now = datetime.now()
#     #timestamp_label = str(now.year) + "-" + str(now.month) + "-" + str(now.day) + "-" + str(now.hour) + "-" + str(now.minute)
#     #.mkdir(SiTAR_folder + timestamp_label)
#     #shutil.copyfile(SiTAR_folder + "arcore-session.mp4", SiTAR_folder + timestamp_label + "/arcore-session.mp4")
    
#     # Wait for playback to complete
#     print("Trajectory is  " + str((wait_time - 5)/5) + " seconds long, waiting " + str(wait_time) + " seconds")
#     time.sleep(wait_time)
        
#     # Close playback app
#     os.system(adb_location + "adb shell am force-stop " + playback_package_name)
    
#     # Pull trajectory estimates from playback AR device
#     print("Pulling trajectories...")
#     for i in range(1,num_playbacks+1):
#         os.system(adb_location + "adb pull /sdcard/Android/data/" + playback_package_name + "/files/trajectory_" + str(i) + ".txt " + SiTAR_folder + "/trajectories")
    
# Perform pairwise trajectory evaluations
file_pattern = "/home/ziwen/ORBSLAM3/common_results_correct_timestamp/f_dataset-V103_monoi_iteration_*.txt"
trajectory_files = glob.glob(file_pattern)
num_playbacks = len(trajectory_files)
# num_playbacks=10
trials = list(range(1, num_playbacks+1))
pairs = itertools.combinations(trials,2)
for count, pair in enumerate(pairs):
    ref_file = trajectory_files[pair[0]-1]
    est_file = trajectory_files[pair[1]-1]
    traj_ref = file_interface.read_tum_trajectory_file(ref_file)
    traj_ref.timestamps = traj_ref.timestamps / 1e9 # Convert timestamps to seconds for TUM as Euroc/TUM-VI are in nanoseconds
    traj_est = file_interface.read_tum_trajectory_file(est_file)
    traj_est.timestamps = traj_est.timestamps / 1e9
    
    max_diff = 0.01     
    traj_ref, traj_est = sync.associate_trajectories(traj_ref, traj_est, max_diff)        
    traj_est_aligned = copy.deepcopy(traj_est)
    traj_est_aligned.align(traj_ref, correct_scale=False, correct_only_scale=False)         
    rpe_metric = metrics.RPE(pose_relation=metrics.PoseRelation.translation_part, delta=10, delta_unit=metrics.Unit.frames, all_pairs=True)
    rpe_metric.process_data((traj_ref, traj_est))
    rpe_stat = rpe_metric.get_statistic(metrics.StatisticsType.rmse)
    print(rpe_stat)
    rpe_stats = rpe_metric.get_all_statistics()
    pprint.pprint(rpe_stats)
    
    traj_ref_start = copy.deepcopy(traj_ref)
    traj_est_start = copy.deepcopy(traj_est_aligned)
    traj_ref_plot = copy.deepcopy(traj_ref)
    traj_est_plot = copy.deepcopy(traj_est_aligned)
    start_ids = [x - 10 for x in rpe_metric.delta_ids]
    traj_ref_start.reduce_to_ids(start_ids)
    traj_est_start.reduce_to_ids(start_ids)
    traj_ref_plot.reduce_to_ids(rpe_metric.delta_ids)
    traj_est_plot.reduce_to_ids(rpe_metric.delta_ids)
    
    df = pd.DataFrame(None)
    df = pd.DataFrame(list(zip(traj_est_start.timestamps, traj_est_plot.timestamps, rpe_metric.error)),columns =['start', 'end_' + str(pair[0]) + "-" + str(pair[1]), 'error_' + str(pair[0]) + "-" + str(pair[1])])
    if (count == 0):
        df_results = df
    else:
        df_results = pd.merge(df_results,df, on='start', how='outer')
        # df_results = df
    
# Implement desired uncertainty calculation setting here (mean given as example)
df_errors = df.filter(regex='error')
df_results['error_mean'] = df_errors.mean(axis=1)


if(0):
    

    # Sample DataFrame setup (assuming df_results is already defined with your specific error columns)
    # Example columns: 'start', 'error_1-2', 'error_1-3', ... 'error_mean'
    error_columns = [col for col in df_results.columns if 'error_' in col and col != 'error_mean']

    plt.figure(figsize=(14, 7))
    colors = plt.cm.viridis(np.linspace(0, 1, len(error_columns)))  # Generates a color map

    for i, col in enumerate(error_columns):
        plt.plot(df_results['start'], df_results[col], marker='', linestyle='-', label=col, color=colors[i])

    plt.title('Mean Error Over Time for Different Trajectory Pairs')
    plt.xlabel('Start Time')
    plt.ylabel('Error')
    plt.legend(title='Trajectory Pairs', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True)
    plt.show()




# df_results = df_results[df_results.error_mean != 0]
# df_results = df_results[["start", "error_mean"]]
# df_results['start'] = df_results['start'].round(decimals=0).astype(int)
# df_results['start'] = df_results['start'].astype(str).replace('\.0', '', regex=True)
# Save pose error estimates to results.csv
df_results.to_csv('results100.csv', index=False)

# (Optional) Copy trajectories and results to save folder
#for i in range(1,num_playbacks+1):
    #shutil.copyfile(SiTAR_folder + "/trajectories/trajectory_" + str(i) + ".txt", SiTAR_folder + timestamp_label + "/trajectory_" + str(i) + ".txt")
#shutil.copyfile(SiTAR_folder + "results.csv", SiTAR_folder + timestamp_label + "/results.csv")

# #Optional method to handle request from user AR device for pose error estimates results 
# @app.get("/results.csv")
# async def root():
#     return FileResponse(path="results.csv", filename="results.csv", media_type='text/csv')

# #Optional method to handle logging of original timestamps from user AR device
# @app.post("/timestamps")
# def upload(timestamps: UploadFile = File(...)):
#     try:
#         contents = timestamps.file.read()
#         with open(timestamps.filename, 'wb') as f:
#             f.write(contents)
#     except Exception:
#         return {"message": "There was an error uploading the file"}
#     finally:
#         timestamps.file.close()


